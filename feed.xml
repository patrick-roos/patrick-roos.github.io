<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://patrick-roos.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://patrick-roos.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-04T16:45:23+00:00</updated><id>https://patrick-roos.github.io/feed.xml</id><title type="html">blank</title><subtitle>Patrick Roos Personal Website - Computer Science PhD, Artificial Intelligence, Machine Learning, Data Science </subtitle><entry><title type="html">Managing High Technical Talent in Machine Learning and Engineering</title><link href="https://patrick-roos.github.io/blog/2025/managing-high-tech-talent-ml/" rel="alternate" type="text/html" title="Managing High Technical Talent in Machine Learning and Engineering"/><published>2025-01-25T11:40:00+00:00</published><updated>2025-01-25T11:40:00+00:00</updated><id>https://patrick-roos.github.io/blog/2025/managing-high-tech-talent-ml</id><content type="html" xml:base="https://patrick-roos.github.io/blog/2025/managing-high-tech-talent-ml/"><![CDATA[<p>One of the things that makes leading ML and general engineering talent fulfilling and fun for me is the incredibly smart and talented teams and ICs (Individual Contributors) I get to work with. Throughout my career, both in AI/ML services and in data-driven product companies, I’ve looked for and been lucky to find many such high-talent teams—otherwise, I wouldn’t have enjoyed my career and probably wouldn’t even be here writing this. While these high-talent teams have been made up of all kinds of interesting and different individuals, they do all tend to 1) have certain traits that make them exceptional at what they do, but also 2) require a special type of management or leadership.</p> <p>This kind of talent wants to do great work and is technically capable. They don’t care about titles, they see through inefficiency immediately, and they expect managers to operate at a high level. If you want to run a high-performing team, you need to recognize this and manage accordingly. I’ve worked with dozens of technical teams and managers throughout my career and have seen the difference between great and poor leadership. Two aspects that stand out as frequently overlooked or undervalued by poor leaders: leading by example and giving people protection and space to “let them cook”.</p> <h2 id="leading-by-example">Leading by Example</h2> <p>Highly talented technical people respect competence. If you’re leading an ML or engineering team and are always just asking for things and never getting into the doing, that’s a quick path to having the team lose trust or confidence in you. Over time, they will start ignoring you (by necessity), and the morale and output of the team will suffer, eventually leading your high-potential team to mediocrity. Of course, one of the main responsibilities of leaders is to keep the bigger picture in mind and not always “look down the sights,” but there are always opportunities to contribute hands-on, and in my experience, you need to for both trust and understanding.</p> <p>Unfortunately, I’ve seen too many managers believe they can delegate everything and focus solely on “strategy.” That doesn’t work with high-talent technical teams. If your team doesn’t believe you understand their work or the challenges they face (and you won’t if you strictly limit yourself to “managing”), they won’t take your guidance seriously—at least not for long. Stepping in when needed—whether reviewing code, helping debug an issue, doing legwork to clarify a data field, refining documentation, or handling a tough stakeholder negotiation—sets the standard and earns respect.</p> <p>You don’t have to and obviously shouldn’t do the team’s work, but you need to demonstrate that you understand what good work looks like and be able and willing to contribute hands-on when needed. Strong talent knows you have other responsibilities, but even the smallest efforts to take on an IC role when the team is stretched or needs it will be seen, appreciated, and repaid. They need to trust that you understand their challenges, and conversely, you need to trust them—which you can’t do if you don’t have at least a baseline understanding of what it takes to do their work. This brings me to the flip side of trust and the next point:</p> <h2 id="let-them-cook">“Let Them Cook”</h2> <p>Deep work is essential in ML and engineering, and strong talent will not just need and crave this time but also be highly sensitive to infractions upon it. Leaders who constantly interrupt this time not only destroy a team’s ability to get their most valuable work done but also chip away at their morale. In my experience, the worst offenders are managers who don’t understand what goes into the work or how answers are derived. This lack of understanding is often paired with a lack of confidence that manifests as frequent requests for updates, premature demands for results, and excessive processes imposed to maintain a sense of control. “Letting them cook” comes down to two key principles: trusting them and protecting them from chaos.</p> <h3 id="trust-your-ics">Trust your ICs.</h3> <p>Leading by example helps build trust, and as a leader, you should also trust your team’s IC abilities. If you don’t, either you or they are not in the right place. Beyond that, it’s your job to set goals, align on direction, and then let them execute. High-talent individuals know when to reach out and when they need time to figure things out. A good check-in cadence is perhaps a weekly 1-on-1—sometimes even that is too frequent.</p> <p>I like to give my team a simple rule of thumb to ensure we’re aligned: “If you’re stuck for more than two hours without making progress, or if you need clarification on goals, reach out to me. Otherwise, I’ll assume you’re making progress and won’t interrupt you until our weekly 1-on-1.” Along the line of trust, listen to what they’re telling you. They are the ones in the data every day, they understand the intricate challenges and difficulties around the data they have to deal with. Too often I’ve seen managers listen to ICs raise issues around data or integrations and not take them as seriously as they should, sometimes even dismissing the issue outright because it’s inconvenient for their timelines and business goals. This not only erodes trust and morale but creates a snowball of tech debt that will come back around to kill productivity and velocity in the long term.</p> <h3 id="protect-them-from-chaos">Protect them from chaos.</h3> <p>High-talent teams attract organizational chaos. Leadership will always look to them to fix urgent issues or take on sudden reprioritizations. Stakeholders and other teams will seek quick answers on pressing concerns because they know your team can help. A manager’s job is NOT to just pass along requests and delegate tasks—it’s to filter the noise and keep the team focused.</p> <p>A good leader knows when to hold requests back instead of immediately passing them on. They negotiate realistic expectations, intercept distractions before they reach the team, and ensure the team has the space to do their best work. And, coming back to leading by example, a strong leader takes on some of the unavoidable requests themselves to reduce the burden on their team. Great leaders absorb chaos instead of distributing it.</p> <p>A big point to also mention here is context switching. Yes, business priorities may change unexpectedly, and being agile as a team is crucial to maintaining high velocity and working on what provides the most value, but not every reprioritization needs to be passed down immediately. If an IC is two weeks out from finishing a model they’ve been working on for six weeks, it may very well be worth their sanity and sense of accomplishment to give them that time and delay the start on new priorities. More often than not in my experiences, that model they are working on comes back around to being useful in some unexpected but valuable way in the future. It’s your job as a manager to find the right balance and be sensitive to the fact that closing out a project properly will make the ramp-up and transition to the new priority that much faster as ICs can approach it with a clear mind and motivation rather than with a sense of incompleteness and uncertainty.</p> <h2 id="final-thoughts">Final Thoughts</h2> <p>Just like any strong relationship, running a high-performing technical team has to be built on trust. Without it, even the most talented teams will struggle to stay engaged and deliver their best work. Throughout my career, I’ve seen trust break down in two critical ways: managers who fail to lead by example and those who fail to give their teams the space to work. If you want to build and sustain a high-performing technical team, lead by example, trust your team, and let them cook.</p>]]></content><author><name></name></author><category term="ml,"/><category term="management,"/><category term="engineering"/><category term="talent,"/><category term="ICs"/><summary type="html"><![CDATA[One of the things that makes leading ML and general engineering talent fulfilling and fun for me is the incredibly smart and talented teams and ICs (Individual Contributors) I get to work with. Throughout my career, both in AI/ML services and in data-driven product companies, I’ve looked for and been lucky to find many such high-talent teams—otherwise, I wouldn’t have enjoyed my career and probably wouldn’t even be here writing this. While these high-talent teams have been made up of all kinds of interesting and different individuals, they do all tend to 1) have certain traits that make them exceptional at what they do, but also 2) require a special type of management or leadership.]]></summary></entry><entry><title type="html">Using PySpark and Pandas UDFs to Train Scikit-Learn Models Distributedly</title><link href="https://patrick-roos.github.io/blog/2019/pyspark-pandas-udf/" rel="alternate" type="text/html" title="Using PySpark and Pandas UDFs to Train Scikit-Learn Models Distributedly"/><published>2019-02-25T20:09:00+00:00</published><updated>2019-02-25T20:09:00+00:00</updated><id>https://patrick-roos.github.io/blog/2019/pyspark-pandas-udf</id><content type="html" xml:base="https://patrick-roos.github.io/blog/2019/pyspark-pandas-udf/"><![CDATA[<p>Say you find yourself in the peculiar situation where you need to train a whole bunch of scikit-learn models over different groups from a large amount of data. And say you want to leverage Spark to distribute the process to do it all in a scalable fashion.</p> <p>Recently I ran into such a use case and found that by using pandas_udf – a PySpark user defined function (UDF) made available through PyArrow – this can be done in a pretty straight-forward fashion. Pandas UDFs allow you to write a UDF that is just like a regular Spark UDF that operates over some grouped or windowed data, except it takes in data as a pandas DataFrame and returns back a pandas DataFrame. We just need to define the schema for the pandas DataFrame returned.</p> <p>Let’s define this return schema. Assume we have some group_id that we can use to group our data into those portions that will be used to train each model. We’ll return a model with that group_id and since it might good info to have later let’s also return the number of instances within that group that the model was trained with, call it num_instances_trained_with. To store all the trained models we will use the python pickle library to dump the model to a string which we can later load back, call it model_str.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pyspark.sql.types</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># define schema for what the pandas udf will return
</span><span class="n">schema</span> <span class="o">=</span> <span class="nc">StructType</span><span class="p">([</span>
<span class="nc">StructField</span><span class="p">(</span><span class="sh">'</span><span class="s">group_id</span><span class="sh">'</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">()),</span>
<span class="nc">StructField</span><span class="p">(</span><span class="sh">'</span><span class="s">num_instances_trained_with</span><span class="sh">'</span><span class="p">,</span> <span class="nc">IntegerType</span><span class="p">()),</span>
<span class="nc">StructField</span><span class="p">(</span><span class="sh">'</span><span class="s">model_str</span><span class="sh">'</span><span class="p">,</span> <span class="nc">StringType</span><span class="p">())</span>
<span class="p">])</span>
</code></pre></div></div> <p>To define a pandas UDF that will train a scikit-learn model, we need to use the pandas_udf decorator, and since we will take in a pandas DataFrame and return the same we need to define the function as a PandasUDFType.GROUPED_MAP (as opposed to PandasUDFType.SCALAR which would take just a pandas Series). Within the UDF we can then train a scikit-learn model using the data coming in as a pandas DataFrame, just like we would in a regular python application:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pickle</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">pandas_udf</span>
<span class="kn">from</span> <span class="n">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">PandasUDFType</span>

<span class="nd">@pandas_udf</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">functionType</span><span class="o">=</span><span class="n">PandasUDFType</span><span class="p">.</span><span class="n">GROUPED_MAP</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">df_pandas</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">
    Trains a RandomForestRegressor model on training instances
    in df_pandas.

    Assumes: df_pandas has the columns:
                 [</span><span class="sh">'</span><span class="s">my_feature_1</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">my_feature_2</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">my_label</span><span class="sh">'</span><span class="s">]

    Returns: a single row pandas DataFrame with columns:
               [</span><span class="sh">'</span><span class="s">group_id</span><span class="sh">'</span><span class="s">, </span><span class="sh">'</span><span class="s">num_instances_trained_with</span><span class="sh">'</span><span class="s">,
                </span><span class="sh">'</span><span class="s">model_str</span><span class="sh">'</span><span class="s">]
    </span><span class="sh">'''</span>

    <span class="c1"># get the value of this group id
</span>    <span class="n">group_id</span> <span class="o">=</span> <span class="n">df_pandas</span><span class="p">[</span><span class="sh">'</span><span class="s">group_id</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># get the number of training instances for this group
</span>    <span class="n">num_instances</span> <span class="o">=</span> <span class="n">df_pandas</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># get features and label for all training instances in this group
</span>    <span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">my_feature_1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">my_feature_2</span><span class="sh">'</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="sh">'</span><span class="s">my_label</span><span class="sh">'</span><span class="p">;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df_pandas</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">df_pandas</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>

    <span class="c1"># train this model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>

    <span class="c1"># get a string representation of our trained model to store
</span>    <span class="n">model_str</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># build the DataFrame to return
</span>    <span class="n">df_to_return</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">([</span><span class="n">group_id</span><span class="p">,</span> <span class="n">num_instances</span><span class="p">,</span> <span class="n">model_str</span><span class="p">],</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">group_id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">num_instances_trained_with</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">model_str</span><span class="sh">'</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">df_to_return</span>
</code></pre></div></div> <p>Now, assuming we have a PySpark DataFrame (df) with our features and labels and a group_id, we can apply this pandas UDF to all groups of our data and get back a PySpark DataFrame with a model trained (stored as a pickle dumped string) on the data for each group:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_trained_models</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">'</span><span class="s">group_id</span><span class="sh">'</span><span class="p">).</span><span class="nf">apply</span><span class="p">(</span><span class="n">train_model</span><span class="p">)</span>
</code></pre></div></div> <p>Note that the models will each be trained on a single Spark executor so some caution may be necessary to not blow up the executor memory if the data within each group is too large for a single executor to hold and do the model training in memory.</p>]]></content><author><name></name></author><category term="python,"/><category term="pyspark,"/><category term="machine-learning,"/><category term="pandas"/><summary type="html"><![CDATA[Say you find yourself in the peculiar situation where you need to train a whole bunch of scikit-learn models over different groups from a large amount of data. And say you want to leverage Spark to distribute the process to do it all in a scalable fashion.]]></summary></entry><entry><title type="html">Mining for Viral Expression in Human Cancer</title><link href="https://patrick-roos.github.io/blog/2018/mining-for-viral-expression-cancer/" rel="alternate" type="text/html" title="Mining for Viral Expression in Human Cancer"/><published>2018-04-07T12:34:00+00:00</published><updated>2018-04-07T12:34:00+00:00</updated><id>https://patrick-roos.github.io/blog/2018/mining-for-viral-expression-cancer</id><content type="html" xml:base="https://patrick-roos.github.io/blog/2018/mining-for-viral-expression-cancer/"><![CDATA[<p>Human papillomavirus (HPV) is known to be linked to cervical cancers in humans, and luckily HPV vaccines have become fairly common. What viruses in general play a role in cancers, and to what extent, is still a somewhat open question. The vast amount of cancer and virus genomic datasets we have at the National Cancer Institute through programs like the <a href="https://www.cancer.gov/ccg/research/genome-sequencing/tcga">Cancer Genome Atlas Program</a> (TCGA) and <a href="https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/">NCBI Virus</a>, combined with sequence alignment and classification software like <a href="https://bowtie-bio.sourceforge.net/bowtie2/index.shtml">Bowtie 2</a> or <a href="https://ccb.jhu.edu/software/kraken/">Kraken</a> developed by colleagues at John’s Hopkins University presented a great opportunity to explore this question further and help solidify some answers.</p> <p>With these resources, we analyzed large cancer genomic datasets for microbial DNA and RNA expression to check for correlations between various virus expression patterns in cancer vs. normal tissue, including cervical, ovarian, lung, and brain cancers. Our findings indicated that while the correlation of HPV and cervical cancer was by far the clearest, which was no surprise, there was some significant prevalence of HPV in North American cases of ovarian cancer.</p> <p>For more info see the full paper: <a href="https://pubmed.ncbi.nlm.nih.gov/25721614/">In North America, some ovarian cancers express the oncogenes of preventable human papillomavirus HPV-18</a>.</p>]]></content><author><name></name></author><category term="data-mining,"/><category term="bioinformatics,"/><category term="cancer"/><summary type="html"><![CDATA[Human papillomavirus (HPV) is known to be linked to cervical cancers in humans, and luckily HPV vaccines have become fairly common. What viruses in general play a role in cancers, and to what extent, is still a somewhat open question. The vast amount of cancer and virus genomic datasets we have at the National Cancer Institute through programs like the Cancer Genome Atlas Program (TCGA) and NCBI Virus, combined with sequence alignment and classification software like Bowtie 2 or Kraken developed by colleagues at John’s Hopkins University presented a great opportunity to explore this question further and help solidify some answers.]]></summary></entry><entry><title type="html">Evolution of Third Party Punishment - Publication and Media Coverage</title><link href="https://patrick-roos.github.io/blog/2013/evolution-of-third-party-punishment/" rel="alternate" type="text/html" title="Evolution of Third Party Punishment - Publication and Media Coverage"/><published>2013-12-20T10:21:00+00:00</published><updated>2013-12-20T10:21:00+00:00</updated><id>https://patrick-roos.github.io/blog/2013/evolution-of-third-party-punishment</id><content type="html" xml:base="https://patrick-roos.github.io/blog/2013/evolution-of-third-party-punishment/"><![CDATA[<p>Our recent paper on the evolution of third-party punishment behavior was published in Proceedings for The Royal Society B! Here is a <a href="https://pubmed.ncbi.nlm.nih.gov/24335985/">link to the full paper</a>.</p> <p>It subsequently attracted considerable media coverage, including a press releases at Bloomberg News: <a href="https://www.bloomberg.com/news/articles/2013-12-16/why-some-communities-police-themselves-while-others-don-t">Why Some Communities Police Themselves, While Others Don’t</a>, Science Daily: <a href="https://www.sciencedaily.com/releases/2013/12/131210193136.htm#:~:text=The%20model%20results%20suggest%20that,individual%20who%20metes%20out%20punishment.">Evolution of ‘third party punishment’</a>, the Maryland Institute for Systems Research: <a href="https://isr.umd.edu/news/story/crime-and-punishment-interdisciplinary-researchers-explain-third-party-evolution">Crime and punishment: interdisciplinary researchers explain ‘third party’ evolution</a>.</p> <p>To excerpt from the latter:</p> <blockquote> <p>Game theory has been used before in social science work, but this is the first time that cross-cultural psychologists and computational game theorists have collaborated to examine the evolution of third-party punishment.</p> </blockquote>]]></content><author><name></name></author><category term="evolutionary-game-theory,"/><category term="culture,"/><category term="third-party-punishment"/><summary type="html"><![CDATA[Our recent paper on the evolution of third-party punishment behavior was published in Proceedings for The Royal Society B! Here is a link to the full paper.]]></summary></entry><entry><title type="html">Defended my PhD Thesis - Evolutionary game theoretic modeling of decision making and culture</title><link href="https://patrick-roos.github.io/blog/2012/defended-phd-thesis/" rel="alternate" type="text/html" title="Defended my PhD Thesis - Evolutionary game theoretic modeling of decision making and culture"/><published>2012-12-01T15:30:00+00:00</published><updated>2012-12-01T15:30:00+00:00</updated><id>https://patrick-roos.github.io/blog/2012/defended-phd-thesis</id><content type="html" xml:base="https://patrick-roos.github.io/blog/2012/defended-phd-thesis/"><![CDATA[<p>I defended my PhD thesis! :D</p> <p>This work focused on employing evolutionary game theoretic approaches that combine theoretical analysis and multi-agent systems to generate models of the evolution of human decision-making and culture. This work has shown how a large range of population dynamics (resembling imitation learning) result in state-dependent risk preferences under sequential choice, and how this principle facilitates the evolution of cooperation in classic game-theoretic games where cooperation entails risk.</p> <p>The full thesis can be found here: <a href="https://www.proquest.com/docview/1426818101?pq-origsite=gscholar&amp;fromopenview=true&amp;sourcetype=Dissertations%20&amp;%20Theses">Evolutionary game theoretic modeling of decision making and culture</a></p> <p>Here is the abstract:</p> <blockquote> <p>Evolutionary Game Theory (EGT) has become an attractive framework for modeling human behavior because it provides tools to explicitly model the dynamics of behaviors in populations over time and does not require the strong rationality assumptions of classical game theory. Since the application of EGT to human behavior is still relatively new, many questions about human behavior and culture of interest to social scientists have yet to be examined through an EGT perspective to determine whether explanatory and predictive rather than merely descriptive insights can be gained. In this thesis, informed by social science data and under close collaboration with social scientists, I use EGT-based approaches to model and gain a qualitative understanding of various aspects of the evolution of human decision-making and culture. The specific phenomena I explore are i) risk preferences and their implications on the evolution of cooperation and ii) the relationship between societal threat and the propensity with which agents of societies punish norm-violating behavior.</p> </blockquote>]]></content><author><name></name></author><category term="evolutionary-game-theory,"/><category term="culture,"/><category term="multi-agent-systems"/><summary type="html"><![CDATA[I defended my PhD thesis! :D]]></summary></entry></feed>